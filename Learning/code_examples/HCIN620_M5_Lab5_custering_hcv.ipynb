{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"HCIN620_M5_Lab5_Clustering.ipynb","provenance":[{"file_id":"140aoRh4rT_spW9wOywF4oKykZIj1370k","timestamp":1609266306731}],"collapsed_sections":[],"toc_visible":true}},"cells":[{"cell_type":"markdown","metadata":{"id":"Pxxp7S6uOcOW"},"source":["$\\color{brown}{\\text{HCIN 620 Lab 5 Unsupervised Clustering Algorithms}}$\n","\n","The following resources have been used to generate this notebook\n","\n","https://realpython.com/k-means-clustering-python/\n","\n","Data is located at UCI repository. Check the link for further information. \n","\n","https://archive.ics.uci.edu/ml/datasets/HCV+data\n","\n","The k-means clustering method is an unsupervised machine learning technique used to identify clusters of data objects in a dataset. There are many different types of clustering methods, but k-means is one of the oldest and most approachable. These traits make implementing k-means clustering in Python reasonably straightforward, even for novice programmers and data scientists.\n","\n","If you’re interested in learning how and when to implement k-means clustering in Python, then this is the right place. You’ll walk through an end-to-end example of k-means clustering using Python, from preprocessing the data to evaluating results.\n","\n","In this tutorial, you’ll learn:\n"," \n","* What k-means clustering is\n","\n","* When to use k-means clustering to analyze your data\n","\n","* How to implement k-means clustering in Python with scikit-learn\n","\n","* How to select a meaningful number of clusters </div>\n","\n","Notebook by Reza Afra, Ph.D. and Barbara Berkovich, Ph.D., M.A.\n","\n","Last update December 29, 2020\n"]},{"cell_type":"markdown","metadata":{"id":"MLj1Mdai5f9a"},"source":["# **Step 1 Environment Setup**"]},{"cell_type":"markdown","metadata":{"id":"WROQuTdSkVz5"},"source":["##Import Code Libraries.\n","\n","The first set of libraries is the same as Modules 2-4 with the addition of [plotly.express ](https://plotly.com/python/plotly-express/)\n","\n","**Run Import 1.**\n"]},{"cell_type":"code","metadata":{"id":"h9bOx5_ekp0L"},"source":["##  Import 1. Data manipulation and visualization libraries\n","\n","import pandas as pd             # data manipulation library\n","import io                       # Helps with Input/output of csv files\n","import numpy as np              # Fast array operations    \n","import matplotlib.pyplot as plt # a library to plot nice graphs\n","plt.style.use('ggplot') \n","import seaborn as sns           # plot style and color on next line\n","sns.set(style=\"white\", palette=\"muted\", color_codes=True) \n","\n","import plotly.express as px     # for EDA data scattermatrix visualization\n","\n","print('Import 1 complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1SRNx5HZyUl"},"source":["Scikit Learn (Rhymes with psychic) is the main machine learning library in Python. The [scikit-learn.org](https://scikit-learn.org/stable/) maintains the open source code. </br>\n","\n","**Question 1**  Give a very brief description of the following sklearn classes*:\n","\n","1. KMeans   [Type answer here] \n","2. PCA      [Type answer here]\n","3. Pipeline [Type answer here] \n","\n","'* *Note that classes in this context refers to subprograms within the code libaries. Do not confuse this with the term classes as it is used in machine learning classification models.*\n"]},{"cell_type":"markdown","metadata":{"id":"kR_Aw8HKyyEA"},"source":["**Run the code to complete the import 2.**"]},{"cell_type":"code","metadata":{"id":"LldIiRfufAD5"},"source":["from sklearn.preprocessing import LabelEncoder \n","from sklearn.preprocessing import MinMaxScaler\n","from sklearn.pipeline import Pipeline\n","from sklearn.decomposition import PCA\n","from sklearn.cluster import KMeans\n","from sklearn.metrics import silhouette_score, adjusted_rand_score\n","\n","\n","print('Import 2 complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0X2CsbiN3np8"},"source":["# **Step 2 Data Cleaning**"]},{"cell_type":"markdown","metadata":{"id":"CoNA36yjjByq"},"source":["**Use the Folder and upload icons (left) to upload data-lab-5-hcv.csv**\r\n","\r\n","**Run the code** to read the hepatitis C virus (HCV) data in the Colab Runtime Environment.\r\n"]},{"cell_type":"code","metadata":{"id":"pM6aAJDPkIr9"},"source":["hcv = pd.read_csv(\"data-lab-5-hcv.csv\")\n","print('Data connection complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XumqlMjyjTS6"},"source":["**Question 2** Another way to view the data in Python is simply to use the name of the data frame.  In this case we've read the input file into a data frame call **hcv**. Enter that name on the next command line. </br>\n","**Run it.**"]},{"cell_type":"code","metadata":{"id":"40d6PVGnjqpN"},"source":["# Answer 2: Add the name of the data frame below\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"RuAxrgrYnhKq"},"source":["##Handle missing values\n","\n"]},{"cell_type":"markdown","metadata":{"id":"bobHfNHfl4SH"},"source":["Run the code below to check for null values. "]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"6e52e4345af572ad533c561f955789c42dbbb4e7","id":"AGO2hxllKdrH"},"source":["hcv.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-A3r-troEjE"},"source":["**Question 3** </br>\r\n","\r\n","Edit this text cell to answer the questions below: \r\n","1. List the variables with NaN (not a number) values. [Type Answer Here]\r\n","2. List the ALP row numbers that contain NaN          [Type Answer Here]\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"9AyB9amy1L9V"},"source":["**Question 4**\r\n","Use the fillna command using the 'ffill' method to replace NaN with the value of the previous row. </br>Print the data frame as  you did in Question 2 to confirm that NaN has been replaced.\r\n","\r\n","**Run the fillna step**"]},{"cell_type":"code","metadata":{"id":"7QW16N4x1_Sw"},"source":["# Answer 4: Add code below to fill the missing values.\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"gfGawiGp3Q3T"},"source":["**Question 5** In the original dataset (Question 2), lines 613 and 614 had missing values (NaN) for the variable ALP. Answer the following questions about the results of the 'ffill' method.\r\n","\r\n","\r\n","1. What is the new values of ALP on rows 613 and 614? \r\n","   \r\n","   [Type answer here]\r\n","2. Where did that number come from? \r\n","   \r\n","   [Type answer here]\r\n","3. How does this differ from the backfill method used in Lab 2 (Question 11)?\r\n"," \r\n","   [type answer here]\r\n","\r\n","4.  What is the term we use when we fill the missing values with \"guesses\"?\r\n","   [type answer here]\r\n","\r\n","5.  What is another way we could handle the missing data?\r\n","    [type answer here]\r\n","\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"NLHhLbNqj0_A"},"source":["##Drop Unnecessary Variables\r\n","\r\n","**Question 6** The first column,'Unnamed:  0' is a dummy variable in place of the patient id (removed for privacy).</br>Enter and run the code to drop the column 'Unnamed: 0'</br>Print the dataframe as you have in previous steps to verify that the NaN values have been replaced.</br>\r\n","\r\n","NOTE: Python has context sensitive help. Type in **hcv.dr** and pause to see the help in a pop-up window.\r\n","</br>\r\n","\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"seMjc8ztXD88"},"source":["# Answer 6:  Drop the columns 'Unnamed: 0' and 'Category' \r\n","\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"WAtpOTUJdJVI"},"source":["# **Step 3 Exploratory Data Analysis (EDA)**\r\n"]},{"cell_type":"markdown","metadata":{"id":"FGT9S2X-4mfE"},"source":["##Scatter Matrix\r\n","\r\n","**Category** contains the code indicating the diagnosis.\r\n","0=Blood donor (undiagnosed)\r\n","0s=suspect blood donor (suspected of liver disease, unconfirmed)\r\n","1=Hepatitis\r\n","2=Fibrosis\r\n","3=Cirrhosis\r\n","If we were using a supervised machine learning technique, this column might be the target and the values would be training labels. </br>\r\n","Since we are using and unsupervised technique, we will just use Category in our visual data exploration, and not in the actual clustering algorithm.\r\n","\r\n","Read about the plotly.express [scatter_matrix](https://plotly.com/python/splom/)\r\n","\r\n","**Run the plotly command below which plots the correlations between the labs for each value of Category.**\r\n"]},{"cell_type":"code","metadata":{"id":"RYv7vE8tdZDV"},"source":["# Let's explore the relationship between features using the plotly.express (px) library\r\n","\r\n","fig = px.scatter_matrix(hcv,\r\n","    dimensions=list(hcv.drop(columns=\"Category\").columns),\r\n","    color=\"Category\")\r\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"EwiV0WstBTLR"},"source":["**Question 7**  </br>\r\n","Study the scatter matrix. Can you see cells where the data is well separated, and would be a good candidate for clustering? Edit this text box to record your answers below.\r\n","\r\n","1. List the  columns where the category colors *are* well separated across multiple rows.\r\n","\r\n","[Type answer here]\r\n","\r\n","2. List the columns where the category colors *are not* well separated across multiple rows. \r\n","\r\n","[Type answer here]\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"ruJwKJPBEoA8"},"source":["Since we are working with a multidimensional array, we can only visualize the location of dots on a plane. We can zoom in on a single cell of the scatter matrix to see more detail.\r\n","\r\n","**Run the next code cell** to zoom in on the plot of CHE vs CHOL."]},{"cell_type":"code","metadata":{"id":"tHW4gdWbFNo1"},"source":["##Scatter matrix on CHE, CHOL only \r\n","fig = px.scatter_matrix(hcv,      \r\n","    dimensions=['CHE', 'CHOL'],\r\n","    color='Category')\r\n","fig.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8Q7kZuuNRhX8"},"source":["**Question 8**\r\n","\r\n","\r\n","With the increased resolution in these plots, how might you interpret the relationship between CHE, CHOL and the category information?\r\n","\r\n","[Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"g2XLIFByTbHq"},"source":["There are no fixed rules for visualizing the relationships within this data. One can iterate two by two matricies for other columns as we have just done.\r\n","</br></br>\r\n","*At the  beginnning of any analysis do a little homework to increase your clinical understanding of the data elements. Whenever possible seek collaboration with a trained clinician to be aware of known correlations.*\r\n","</br></br>\r\n","\r\n","##Heatmap\r\n","\r\n","**Run the code below** to generate a heatmap\r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"AaPsdIpzUJhY"},"source":["# Look at correlations more closely\r\n","corr = hcv.corr()\r\n","# Generate a mask for the upper triangle\r\n","mask = np.triu(np.ones_like(corr, dtype=bool))\r\n","\r\n","# Set up the matplotlib figure\r\n","f, ax = plt.subplots(figsize=(11, 9))\r\n","\r\n","# Generate a custom diverging colormap\r\n","cmap = sns.diverging_palette(230, 20, as_cmap=True)\r\n","\r\n","# Draw the heatmap with the mask and correct aspect ratio\r\n","sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0,\r\n","            square=True, linewidths=.5, cbar_kws={\"shrink\": .5});"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"wEribiGhAFbL"},"source":["##Correlation Matrix\r\n","\r\n","**Question 9**\r\n","\r\n","Enter the command to generate a correlation matrix.\r\n","\r\n","**Run the corr command**"]},{"cell_type":"code","metadata":{"id":"tbUIPUaQUI4w"},"source":["# Answer 9: Type the command to print correlation matrix in this cell, and run.\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y686JUcw6GHj"},"source":["##Preprocessing\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"WxeSObPX4_bo"},"source":["##Encode the data\r\n"]},{"cell_type":"markdown","metadata":{"_uuid":"b5c5638d94dd67c30fa6e0937b0f7147ab30ae76","id":"R5WkOEJmKdrK"},"source":["Since there is no ordinal relationship among the category labels, the following code encodes these as separate columns of ones and zeros.\n","\n","**Run the encoding.**\n"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"9a65199cbbaa94b4a9edf744e23529d4e842cd6d","id":"oKmS4MjlKdrL"},"source":["#Encoding \n","true_label_names = hcv['Category']\n","\n","label_encoder = LabelEncoder()\n","true_labels = label_encoder.fit_transform(true_label_names)\n","hcv = pd.get_dummies(hcv, dtype=float)\n","hcv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"mWb_DfeCCIcL"},"source":["**Question 10** The original Category column has been transformed.\r\n","\r\n","How many category columns are there now?\r\n","\r\n","**Answer 10**\r\n","\r\n","[Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"GQtdGfTEX6E7"},"source":["##Pipeline\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"_uuid":"000677f443ee8078ea2fd98e7db6710c596cf4de","id":"jmtkt1gZKdrO"},"source":["In practical machine learning pipelines, it’s common for the data to undergo multiple sequences of transformations before it feeds into a clustering algorithm. You learned about the importance of one of these transformation steps, feature scaling in an earlier lab. An equally important data transformation technique is dimensionality reduction, which reduces the number of features in the dataset by either removing or combining them.\r\n","Dimensionality reduction techniques help to address a problem with machine learning algorithms known as the curse of dimensionality. In short, as the number of features increases, the feature space becomes sparse. This sparsity makes it difficult for algorithms to find data objects near one another in higher-dimensional space.\r\n","\r\n","###Dimensionality Reduction using Principal Component Analysis (PCA)\r\n","PCA is one of many dimensionality reduction techniques. It transforms the input data by projecting it into a lower number of dimensions called components. The components capture the variability of the input data through a linear combination of the input data’s features.\r\n","\r\n","The next code block is another application of scikit-learn pipelines. In Lab 4, we used a pipeline to scale the variables, and assign to the x and y values for regression. In this lab, we will use the pipeline to scale the numeric data and perform PCA dimensionality reduction in preparation for the clustering algorithm.\r\n","\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"JOq6Pym7FajV"},"source":["###MinMaxScaler\r\n","\r\n","The pipeline will implement an alternative to the StandardScaler class called MinMaxScaler for feature scaling. You use MinMaxScaler when you do not assume that the shape of all your features follows a normal distribution.\r\n","\r\n","**Run the pipeline.**"]},{"cell_type":"code","metadata":{"id":"e7-H2s1TT5R3"},"source":["label_encoder.classes_\r\n","n_clusters = len(label_encoder.classes_)\r\n","\r\n","# Dimensionality reduction starts here\r\n","preprocessor = Pipeline(\r\n","     [\r\n","         (\"scaler\", MinMaxScaler()),\r\n","         (\"pca\", PCA(n_components=2, random_state=42)),\r\n","     ]\r\n",")\r\n","\r\n","print('MinMaxScaler and PCA pipline complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N8dWrOIEWdlj"},"source":["# **Step 4 Build the Model**"]},{"cell_type":"markdown","metadata":{"id":"OoIwsfR-UAE8"},"source":["##KMeans Clustering Algorithm\r\n","\r\n","Now that you’ve built a pipeline to process the data, you’ll build a separate pipeline to perform k-means clustering. You’ll override the following default arguments of the KMeans class:</br>\r\n","**init=k-means++**\" instead of \"random\" to ensure centroids are initialized with some distance between them. In most cases, this will be an improvement over \"random\".\r\n","\r\n","**n_init=50**: You’ll increase the number of initializations to ensure you find a stable solution.\r\n","\r\n","**max_iter=500**: You’ll increase the number of iterations per initialization to ensure that k-means will converge.\r\n"]},{"cell_type":"markdown","metadata":{"id":"uv5jwTEhFvyn"},"source":["**Run the initialization pipeline.**"]},{"cell_type":"code","metadata":{"id":"oKs8VP7QZI2C"},"source":["clusterer = Pipeline(\r\n","    [\r\n","       (\r\n","            \"kmeans\",\r\n","            KMeans(\r\n","                n_clusters=n_clusters,\r\n","                init=\"k-means++\",\r\n","                n_init=50,\r\n","                max_iter=500,\r\n","                random_state=42,\r\n","            ),\r\n","        ),\r\n","    ]\r\n"," )\r\n","\r\n","print('initialization pipline complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"xmGlzQekF_B-"},"source":["**Run the preprocesser and clustering pipeline.**"]},{"cell_type":"code","metadata":{"id":"ft_9FzhiaSHR"},"source":["pipe = Pipeline(\r\n","  [\r\n","       (\"preprocessor\", preprocessor),\r\n","        (\"clusterer\", clusterer)\r\n","    ]\r\n","   )\r\n","print('preprocessing and clustering complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"2CPN0MQtH3lh"},"source":["**Run the code to fit the model to the data.**"]},{"cell_type":"code","metadata":{"id":"tQBycuXHaVGr"},"source":["pipe.fit(hcv)\r\n","\r\n","  "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kfD1b7BabZY4"},"source":["##Evaluate Results\r\n"]},{"cell_type":"markdown","metadata":{"id":"47xg8Sbfbnfy"},"source":["As mentioned earlier, the scale for each of these clustering performance metrics ranges from -1 to 1. A silhouette coefficient of 0 indicates that clusters are significantly overlapping one another, and a silhouette coefficient of 1 indicates clusters are well-separated. An ARI score of 0 indicates that cluster labels are randomly assigned, and an ARI score of 1 means that the true labels and predicted labels form identical clusters.\r\n","\r\n","**Run the code to generate a silhouette coefficient.**"]},{"cell_type":"code","metadata":{"id":"HOAz2TS3bPMu"},"source":["preprocessed_data = pipe[\"preprocessor\"].transform(hcv)\r\n","predicted_labels = pipe[\"clusterer\"][\"kmeans\"].labels_\r\n","silhouette_score(preprocessed_data, predicted_labels)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"p6Ee5ruiJhfw"},"source":["The silhouette value indicates that the model predicted the correct cluster 94.5% of the time. \r\n","\r\n","We can add the predicted_labels column to the hcv dataframe to visually confirm how many predicted_labels match with the categories.\r\n","\r\n","**Run the code to print the hcv data frame with the predicted labels.**\r\n","\r\n","*Note: Scroll data table to the right to see the predicted_labels column.*"]},{"cell_type":"code","metadata":{"id":"dZAR263MdD64"},"source":["hcv['predicted_labels'] = predicted_labels\r\n","hcv"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"aV2bTU1BcRZn"},"source":["Since you specified n_components=2 in the PCA step of the k-means clustering pipeline, you can also visualize the data in the context of the true labels and predicted labels. \r\n","\r\n","**Run the code to plot the results using a pandas DataFrame and the seaborn plotting library.**"]},{"cell_type":"code","metadata":{"id":"sCREzqbfbeCl"},"source":["hcv.drop(columns='predicted_labels', inplace=True)  #drop the predicted labels before plotting\r\n","\r\n","pcadf = pd.DataFrame(\r\n","     pipe[\"preprocessor\"].transform(hcv),\r\n","    columns=[\"component_1\", \"component_2\"],\r\n"," )\r\n","\r\n","pcadf[\"predicted_cluster\"] = pipe[\"clusterer\"][\"kmeans\"].labels_\r\n","pcadf[\"true_label\"] = label_encoder.inverse_transform(true_labels)\r\n","\r\n","plt.figure(figsize=(8, 8))\r\n","\r\n","scat = sns.scatterplot(\r\n","     x=\"component_1\",\r\n","     y=\"component_2\",\r\n","     s=50,\r\n","     data=pcadf,\r\n","     hue=\"predicted_cluster\",\r\n","     style=\"true_label\",\r\n","     palette=\"Set2\",\r\n"," )\r\n","\r\n","scat.set_title(\r\n","    \"Clustering results from HCV Data\"\r\n"," )\r\n","plt.legend(bbox_to_anchor=(1.05, 1), loc=2, borderaxespad=0.0)\r\n","plt.show()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DBecKYClc8l1"},"source":["The visual representation of the clusters confirms the results of the two clustering evaluation metrics. The performance of your pipeline was pretty good. The clusters only slightly overlapped, and cluster assignments were much better than random."]}]}