{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"name":"HCIN620_M3_Lab3_regression_insurance.ipynb","provenance":[{"file_id":"1b3gHJR9eOv5tS9xNleWjoIPM1WkhFzEE","timestamp":1609286586850}],"collapsed_sections":[]}},"cells":[{"cell_type":"markdown","metadata":{"id":"Pxxp7S6uOcOW"},"source":["$\\color{brown}{\\text{HCIN 620 Lab 3 Python Regression Algorithms}}$\n","\n","This notebook was adapted from https://www.kaggle.com/hely333/eda-regression \n","The supervised linear regression model will determine the cost of treatment based on patient insurance data. In real life, the cost of treatment depends on many factors: diagnosis, type of clinic, city of residence, age and so on. This practice dataset has no data on diagnosis, but we have enough other information to practice regression analysis.\n","\n","We'll continue to use the 4-step approach with the following highlights\n","*   Step 1: Environment Setup \n","\n","        import sklearn libraries for data preprocessing and regression analysis\n","*   Step 2: Data Cleaning - check for missing values\n","*   Step 3: Exploratory Data Analysis and data preprocessing\n","         \n","         Encode Categorical Variables\n","         Select Targets and Features\n","         Assign Targets and Features to linear regression variables x and y\n","         Scale the data\n","         Split the data\n","*   Step 4: Build & Evaluate the Models\n","\n","        Linear Regression model\n","\n","\n","\n","[Data Dictionary](https://www.kaggle.com/hely333/eda-regression/data) \n","\n","\n","Notebook by Reza Afra, Ph.D. and Barbara Berkovich, Ph.D., M.A.\n","\n","Last update December 31, 2020"]},{"cell_type":"markdown","metadata":{"id":"ia6_JRmKciog"},"source":["# **STEP 1: Environment Setup**"]},{"cell_type":"markdown","metadata":{"id":"WROQuTdSkVz5"},"source":["**Import code libraries**\n","The first set of libraries is the same as Module 2 with the addition of ([numpy.org](https://numpy.org)) to handle the array processing. </br>\n","**Run Import 1.**\n"]},{"cell_type":"code","metadata":{"id":"h9bOx5_ekp0L"},"source":["import pandas as pd             # data manipulation library\n","import io                       # helps with input/output of csv files\n","import matplotlib.pyplot as plt # a library to plot nice graphs\n","plt.style.use('ggplot') \n","import seaborn as sns           # plot style and color on next line\n","sns.set(style=\"white\", palette=\"muted\", color_codes=True) \n","import numpy as np              # Fast array operations    \n","\n","print('Import 1 complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"J1SRNx5HZyUl"},"source":["Scikit Learn (Rhymes with psychic) is the main machine learning library in Python. The [scikit-learn.org](https://scikit-learn.org/stable/) maintains the open source code. </br>\n","\n","**Question 1** Comment each line code in the sklearn imports below to briefly describe how each library is used. Start the inline comments with a #. The first one has been done for you. \n","\n","**Run the code to complete the import 2.**"]},{"cell_type":"code","metadata":{"id":"LldIiRfufAD5"},"source":["from sklearn.preprocessing import LabelEncoder             #Changes categorical text data to numeric\n","from sklearn.preprocessing import StandardScaler           #\n","from sklearn.model_selection import train_test_split       #\n","from sklearn.linear_model import LinearRegression          #\n","from sklearn.metrics import r2_score                       #\n","from sklearn.metrics import mean_squared_error             #\n","from sklearn.ensemble import RandomForestRegressor         #\n","\n","print('Import 2 complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"5_QgiFJXprQn"},"source":["#**STEP 2: Data Cleaning**"]},{"cell_type":"markdown","metadata":{"_uuid":"30e2ecc0679548b3d7dc884e02a4213304d46843","id":"M54X4Ia8KdrE"},"source":["**Use the Folder and upload icons (left) to upload data-lab-3-insurance.csv**\n"]},{"cell_type":"markdown","metadata":{"id":"CoNA36yjjByq"},"source":["**Run the code** to read the insurance data in the Colab Runtime Environment."]},{"cell_type":"code","metadata":{"id":"pM6aAJDPkIr9"},"source":["data = pd.read_csv('data-lab-3-insurance.csv')\n","print('Data connection complete')\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"XumqlMjyjTS6"},"source":["**Question 2** Insert the Python command to display first 5 rows of data. </br>\n","Run it."]},{"cell_type":"code","metadata":{"id":"40d6PVGnjqpN"},"source":["# Add code here to display the first 5 rows of data\n","\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JelQO9FSjRg5"},"source":["**Answer Key 2** data.head()  # Displays first 5 rows of data:\n","Row number, age, sex, bmi, children, smoker, region, charges\n"]},{"cell_type":"markdown","metadata":{"id":"bobHfNHfl4SH"},"source":["**Run the code below to check for null values.**"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"6e52e4345af572ad533c561f955789c42dbbb4e7","id":"AGO2hxllKdrH"},"source":["data.isnull().sum()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"r-A3r-troEjE"},"source":["**Question 3**  Interpret the results of the null test. What actions, if any are required to handle nulls?\r\n","\r\n","**Answer 3** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"1PmsD0-bmeCM"},"source":["# **STEP 3: Exploratory Data Analysis(EDA) and Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"N8dWrOIEWdlj"},"source":["##Encode Categorical Variables\r\n"]},{"cell_type":"markdown","metadata":{"_uuid":"b5c5638d94dd67c30fa6e0937b0f7147ab30ae76","id":"R5WkOEJmKdrK"},"source":["\n","The categorical variables in our data are sex, smoker and region.\n","Since the regression model can't handle text directly, we need to encode the categorical data as numeric 1's and 0's. \n","\n","**Run the python code** to encode the categorical variables.\n","\n"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"9a65199cbbaa94b4a9edf744e23529d4e842cd6d","id":"oKmS4MjlKdrL"},"source":["# from sklearn.preprocessing import LabelEncoder\n","#sex\n","le = LabelEncoder()\n","le.fit(data.sex.drop_duplicates()) \n","data.sex = le.transform(data.sex)\n","# smoker or not\n","le.fit(data.smoker.drop_duplicates()) \n","data.smoker = le.transform(data.smoker)\n","#region\n","le.fit(data.region.drop_duplicates()) \n","data.region = le.transform(data.region)\n","data.head()    # Display the changes\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"000677f443ee8078ea2fd98e7db6710c596cf4de","id":"jmtkt1gZKdrO"},"source":["A few words about coding \"region\". In general, categorical variables with large variability are best encoded using OneHotEncoder and so on.  But in this case, nothing will change, because there is no special order in which the regions would be listed. "]},{"cell_type":"markdown","metadata":{"id":"c6m1N7Zbq4I_"},"source":["##Select Targets and Features\n","\n","**The Target is what we want to predict.** In a regression problem it is a continuous numeric variable.\n","Since we are primarily interested in the charges, that will be our target.\n","\n","**The Features are variables used by the model to predict the target.**\n","Possible features in our dataset include:\n","age, sex, bmi, children, smoker and region.  \n","\n","**Feature Engineering** is the process of optimizing the model features.\n","\n","In this case, we wish to predict charges, so let's see which variables have the highest correlation with 'charges'.\n","\n","Run the correlation command."]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"d3db3486b773659048a51d8c28f8788a7b198daa","id":"NmI8VKDcKdrO"},"source":["data.corr()['charges'].sort_values()"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Lbkx_CVHryWM"},"source":["**Question 4** What are the top three features correlated with charges?\n","\n","\n","**Answer 4** [Type answer here]\n"]},{"cell_type":"markdown","metadata":{"id":"tPD23xhIsMgB"},"source":["A heatmap is a useful plot to further explore correlations between the features and target. \r\n","**Run the Python code to produce the heatmap. **"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"cd7124870e1725dd35d464c020d29c4cb0a05a96","id":"G6KKJa3tKdrR"},"source":["f, ax = plt.subplots(figsize=(10, 8))  \n","corr = data.corr()\n","sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(240,10,as_cmap=True),\n","            square=True, ax=ax);"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"203d4091c6485da97983482ff56dcb1abe04aad1","id":"JlKoQkYgKdrT"},"source":["Red is the highest correlation. The diagonal red line shows that each variable is 100% correlated with itself. Pink and light blue show weaker correlations.\n","\n","**Question 5** List the top 3 variables correlated with charges in descending order. \n","\n","\n","**Answer 5**\n","\n","1.  [Highest correlation]\n","2.  [Second highest correlation]\n","3.  [Third highest correlaton]\n"]},{"cell_type":"markdown","metadata":{"_uuid":"d81b82eedfea8f1312c8a34d77c3d131edd254e8","id":"ztrOICNJKdrU"},"source":["Next, let's look at the distribution of charges. This will help us to know how much patients spend on treatment on average.\n","\n","**Run the seaborn plotting function histplot on the variable 'charges'.**"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"ddd108236a1047c740b7bfdf853ba2462c5229d0","id":"PKJJZSitKdrU"},"source":["sns.histplot(data['charges'],color='c');     # Seaborn visualization"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"sRd4ON51GMN-"},"source":["We can break that down further to see the distribution of charges for smokers and non-smokers. \r\n","\r\n","**Run the next code section.**"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"29b7a92f162252184cfd85bcb9c2cba6b381b2cc","id":"sBQnJ5dOKdrX"},"source":["f = plt.figure(figsize=(12,5))\n","\n","ax = f.add_subplot(121)\n","sns.histplot(data[(data.smoker == 1)][\"charges\"],color='c',ax=ax)  # this plots charges when the value of smoker = 1\n","ax.set_title('Distribution of charges for smokers');\n","\n","ax = f.add_subplot(122)\n","sns.histplot(data[(data.smoker == 0)]['charges'],color='b',ax=ax)  # this plots charges when the value of smoker = 0\n","ax.set_title('Distribution of charges for non-smokers');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"f616d144920352e4cab90b011af04c6dd2e3a519","id":"ewzWh9YHKdrZ"},"source":["Check the axes on the two plots.\n","\n","**Question 6** Given the range of charges for smokers vs non-smokers, which group has higher charges?\n","\n","\n","**Answer 6** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"ROrL3KSBIHYb"},"source":["**Question 7** Given the count of smokers vs non-smokers, which group is larger?\r\n","\r\n","**Answer 7** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"dDdHv86XLeX3"},"source":["##Assign targets and features to regression variables x and y\n","\n","For our initial model, we'll select Smoker, Age, BMI as our most promising features. Run the Python code to drop region, sex, and children columns as well as the target 'charges'.  The variable X becomes the features data frame, and the variable Y becomes the target. \n","\n","**Run the code.**"]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"ef0b179e30e38a1b0b3a48de68a9418b0505e16a","id":"wOsE1sG7KdsP"},"source":["# 3.3.2 Choose Features and Target\n","\n","#x = Features. We drop the columns we don't want.\n","x = data.drop(['region', 'sex', 'children', 'charges'], axis ='columns') \n","\n","#y = Target. In this case, charges.\n","y = data.charges \n","\n","print(x)\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"e609af580cd7963b8b6fb4b93c94f2c76d4f9355","id":"lYUkV3BxKdsM"},"source":["##Scale the data\n","\n","It is obvious that our feature columns each have different ranges:\n","Smoker 0-1,\n","Age    0-100,\n","BMI    0-50\n","\n","To avoid the problem of over-valuing age or under-valuing smoker status, we must normalize the data. That means to adjust the variables to a common scale.  Standardization of a dataset is a common requirement for many machine learning estimators: they might behave badly if the individual features do not more or less look like standard normally distributed data (e.g. Gaussian with 0 mean and unit variance). The StandardScalar function subtracts the mean of each column \n","from the data in that column and then divides the result by the standard\n","deviation of that column. \n","\n","**Run the code to scale the data.**\n"]},{"cell_type":"code","metadata":{"id":"CEGGNCZRTPxh"},"source":["\n","scaler = StandardScaler() # Create a scaler object\n","x = scaler.fit_transform(x)\n","y = scaler.fit_transform(np.array(y).reshape(-1, 1)) \n","print('scaling complete')\n","print('new values of array x (age, bmi, smoker)')\n","x"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"BYUxeTP6PoAF"},"source":["##Split the data\n","\n","\n","Since we only have one dataset, we'll split it to create training and testing datasets. The training datasets are like the practice questions your instructors provide prior to an exam. The test data is reserved to see how well the model performs on data it hasn't encountered in the training. </br>\n","Run the code to split the data.\n","\n"]},{"cell_type":"code","metadata":{"id":"XUoWsC_dTP84"},"source":["# Split the data \n","x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n","print('splitting complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zM2iKHNAm2uo"},"source":["#**STEP 4 Model Creation and Evaluation**"]},{"cell_type":"markdown","metadata":{"id":"sA0n6G6vQzJr"},"source":["##Train the Regression Algorithm\n","\n","Because we're using the scikit-learn Python extension, we simply need to define the variable linreg as the output of the LinearRegression function. Then we train the function on the feature (x) and target (y) training data. The trained algorithm can now be called a model.\n","\n"," If we had to write custom code for these functions, it would be so much more difficult!"]},{"cell_type":"code","metadata":{"id":"9UlV_oYdTQGg"},"source":["# Train a linear regression model\n","linreg = LinearRegression()\n","linreg.fit(x_train,y_train) # The actual training step\n","print('3 feature regression training is complete')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"VrxXUWXiRrdY"},"source":["##Test the Model - 3 feature version\n","\n","Now we're ready to see how the model performs against the test data. For each row of data, we calculate a prediction variable, (y_pred) based on the linear regression model applied to the test data (x_test). Run the test."]},{"cell_type":"code","metadata":{"id":"fQtR2-BsTQOg"},"source":["# Testing the model: Predict y_pred based on x_test\n","y_pred = linreg.predict(x_test)\n","print('3 feature model has been appplied to test data')\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"qh3ZRYkTdaiR"},"source":["##Evaluate Model Performance\n","\n","Now we're ready to see how the model performed against the test data. For each row of data, we calculate a prediction variable, (y_pred) based on the linear regression model applied to the test data (x_test). The R-square score has values between 0 and 1. It tells us how well the regression line predicted the actual test values."]},{"cell_type":"code","metadata":{"id":"KQhTdp1EUX-Q"},"source":["# Evaluate results of the prediction on the test data\n","\n","print(f'R-squared: {r2_score(y_true=y_test, y_pred=y_pred):.3}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"_uuid":"4c5794353ab6f5ef69176fcb2028fb29e41a5b5e","id":"AvpoS3eYKdsQ"},"source":["$\\color{brown}{\\text{Result: R-squared = 0.787 Using 3-Feature model}}$\n","\n","**Question 8** Interpret the R-squared score. Is it good, bad, or somewhere in between? Is there a standard R=squared score that defines \"good\" in all cases?\n","\n","**Answer 8** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"PAuQepltXI0v"},"source":["## Train/Test the model again - 6 feature version\n","\n","We established the model's performance using the three variables of Smoker, Age, and BMI. What do you think will happen if we use all the data we have, and include region, sex and children in the model?\n","\n","**Question 9** Will the model perform better, worse of the same with more data?\n","\n","**Answer 9** [Type the answer here]"]},{"cell_type":"markdown","metadata":{"id":"Nj-jhsYBeVlG"},"source":["Run the Python code below run the regression model using all data. The steps are the same as above. We've just combined steps together."]},{"cell_type":"code","metadata":{"id":"dfv3hKfKYZtR"},"source":["# Define features and target\n","x = data.drop(['charges'], axis = 1)  \n","y = data.charges # target\n","\n","print(x)\n"," \n","# Normalize the data\n","scaler = StandardScaler() # Create a scaler object\n","x = scaler.fit_transform(x)\n","y = scaler.fit_transform(np.array(y).reshape(-1, 1))\n","print('scaling complete') \n","\n","# Split the data \n","x_train,x_test,y_train,y_test = train_test_split(x, y, test_size = 0.3, random_state = 0)\n","print('splitting complete')\n","\n","# Create a linear regression object and  train the model\n","linreg = LinearRegression()\n","linreg.fit(x_train,y_train) # The actual training step\n","print('6 feature regression complete')\n","\n","# Predict on the test data\n","y_pred = linreg.predict(x_test)\n","\n","print(f'R-squared: {r2_score(y_true=y_test, y_pred=y_pred):.3}')"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"zBMpbSMxfezk"},"source":["$\\color{brown}{\\text{Result: R-squared = 0.791 using 6-Feature Model}}$\n","\n","**Question 10** What is the difference between the R-squared values for 3- and 6-feature models? Which model would you choose for implementation? Explain your rationale.\n","\n","**Answer 10** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"liBLqcCEEyfS"},"source":["#Try RandomForrestRegressor algorithm\n","\n","There are other regression algorithms that may have advantages over simple linear regression. Let's compare the performance of the sklearn Random Forest Regressor by running the next code section."]},{"cell_type":"code","metadata":{"trusted":true,"_uuid":"15ab5e45c0a99fe16b72e87904297db45fd42ea1","id":"3YlV4degKdsT"},"source":["forest = RandomForestRegressor(n_estimators = 100,\n","                              criterion = 'mse', # mse: mean squared error\n","                              random_state = 1,\n","                              n_jobs = -1)\n","forest.fit(x_train,y_train) # The actual training\n","forest_train_pred = forest.predict(x_train)\n","forest_test_pred = forest.predict(x_test)\n","\n","print('MSE train data: %.3f, MSE test data: %.3f' % (\n","mean_squared_error(y_train,forest_train_pred),\n","mean_squared_error(y_test,forest_test_pred)))\n","print('R-squared train data: %.3f, R-squared test data: %.3f' % (\n","r2_score(y_train,forest_train_pred),\n","r2_score(y_test,forest_test_pred)))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"0VZIlfw-X74I"},"source":["We can see improvement when going from vanilla regression to random forests. If we chose this as our model, consider how it might be used in the management of an Accountable Care Organization. \n","\n","**Question 11** \n","If the same type of input data becomes availabe for prospective patients, \n","how might the prediction of their costs be used by the ACO? \n","Who might make decisions based on these predictions?\n","Is 85% accuracy good enough for that purpose?\n","\n","\n","**Answer 11**  [Type answer here]\n"]}]}