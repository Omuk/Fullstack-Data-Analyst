{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"HCIN620_M2_Lab2_Data_Cleaning.ipynb","provenance":[],"collapsed_sections":[],"toc_visible":true},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","metadata":{"id":"d37rOOqY2vDz"},"source":["#$\\color{brown}{\\text{HCIN 620 Lab 2 Data Cleaning}}$\r\n","In this lab, as with all the others, we'll continue to use the 4-step approach, but we'll go into more detail in Step 2. \r\n","*   Step 1: Environment Setup\r\n","*  **Step 2: Data Cleaning (Evaluate Data Volume, Handle Missing Values, and Identify Outliers)**\r\n","\r\n","\r\n","*   Step 3: Exploratory Data Analysis\r\n","*   Step 4: Build & Evaluate the Models\r\n","\r\n","As you progress in the labs, you'll be asked to apply commands and techniques you've learned in previously.\r\n","\r\n","\r\n","Notebook by Reza Afra, Ph.D. and Barbara Berkovich, Ph.D., M.A.\r\n","\r\n","Last update December 27, 2020\r\n"]},{"cell_type":"markdown","metadata":{"id":"65dAB4YuP623"},"source":["# **Step 1 Environment Setup**\n"," \n","**Importing Libraries**\n","\n","In Module 1 we introduced the concept of Python Code libraries which are sometimes called extensions. By convention, we import those at the beginning of the python program. We'll start with the libraries used in Lab 1, and add the [Seaborn statistical data visualization library](https://seaborn.pydata.org/)\n","\n","\n","**Question 1: Enter the python code from Lab 1 to import the libaries. In addition to that code, Import seaborn as sns, and run it.**"]},{"cell_type":"markdown","metadata":{"id":"hG47roQYANEz"},"source":[""]},{"cell_type":"code","metadata":{"id":"0tWY9yjTC_sn"},"source":["#Question 1 - Type the Import code here below this line"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"79rtC3Hf_Wud"},"source":["\r\n","**Question 1: Enter the python code from Lab 1 to import the libaries and run it.**\r\n","\r\n","**Answer Key 1**    #Type the Import code here below this line\r\n","\r\n","import pandas as pd              # a powerful data manipulation library\r\n","\r\n","import io                        # helps with input/output of csv files\r\n","\r\n","import matplotlib.pyplot as plt  # a library to plot nice graphs. plt is just a short alias\r\n","\r\n","plt.style.use('ggplot')          # just makes plots pretty\r\n","\r\n","import seaborn as sns            # introduce Seaborn \r\n","\r\n","print('Import 1 complete')\r\n","\r\n"]},{"cell_type":"markdown","metadata":{"id":"oYjlvILQQJli"},"source":["\r\n","**Question 2** What is the benefit of importing libraries into your program?\r\n","\r\n","**Answer 2**     [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"4jls3gjTUIDA"},"source":["# **Step 2: Data Cleaning**\n","\n","Let's continue to use the same data as Lab 1.\n","\n","**Use the upload icon to upload data-lab-1&2-diabetes.csv.**\n","\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"VKWhMpA3R9fs"},"source":["The next step is to read the data, so that we can begin to review and clean it. \r\n","To do that we use **read_csv** command from Pandas library to read our .csv file. Then we copy it to a pandas data frame which is an array format with a fixed number rows and columns. Lastly, we use the data.head() command to confirm that the data has been read.\r\n","\r\n","**Question 3: Enter the python code from Lab 1 to read the csv file and show the first 10 rows. Then run it.**"]},{"cell_type":"code","metadata":{"id":"f1TPup8DZcSf"},"source":["#Enter the Lab 1 code to read the csv file.\n","\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"vIwnqf4I_aUt"},"source":["Just as a refresher,\r\n","\r\n","Glucose is a lab value for blood sugar\r\n","\r\n","BP_SYS is the systolic blood pressure\r\n","\r\n","BMI is the Body Mass Index\r\n","\r\n","Age is patient age in years\r\n","\r\n","Insulin_YN indicates that the patient is taking insulin\r\n","\r\n","Of course this data would be meaningless without dates, but we'll just assume that one row of data per patient was collected today."]},{"cell_type":"markdown","metadata":{"id":"lhSPLAY4Verz"},"source":["Pandas has many uses including reading various file types. Follow the hyperlink to see \r\n","[PANDAS input formats](https://pandas.pydata.org/pandas-docs/stable/reference/io.html).\r\n","\r\n","**Question 4** List 3 additional file types from the PANDAS Input/Output section that you might need in the future.\r\n","\r\n","\r\n","**Answer 4**    \r\n","\r\n","* [File type 1]\r\n","* [File type 2]\r\n","* [File type 3]"]},{"cell_type":"markdown","metadata":{"id":"uodoa5ncBqnE"},"source":["## Evaluate Data Volume\r\n"]},{"cell_type":"markdown","metadata":{"id":"Opg8_PKAAh_Z"},"source":["\r\n","It's important to know how much data we're starting with. Remember, that we may lose some rows or columns during data cleaning, and we also need to split the dataset for training and testing. \r\n","\r\n","**Question 5** Enter the code to display the counts of rows and columns. Then run it. \r\n","\r\n"]},{"cell_type":"code","metadata":{"id":"76MAAqs8BGrK"},"source":["#Enter the code to display row and column counts\r\n","\r\n","\r\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"c19IzZq5YMbQ"},"source":["It's important to identify which columns you wish to include in your analysis. These are called features, and are used in the prediction of new data.\r\n","\r\n","Many factors must be considered in a thorough analysis of whether a particular dataset is sufficient for any given use case. For the simple cases we're starting out with, let's apply the following heuristic...\r\n","\r\n","For a categorical target, a model needs 50 times more rows than the number of columns. For a numeric target, a model needs 200 times more rows than the number of columns.\r\n","\r\n","**Question 6** Does this dataset have enough data to predict (list categorical example)?\r\n","\r\n","\r\n","**Answer 6**     [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"wbHejglwdgzG"},"source":[" \r\n","\r\n","**Question 7** Does the dataset have enough data to run a regression analysis to predict a continuous variable (such as the probability that their glucose reading is <140)?\r\n","\r\n","\r\n","**Answer 7**     [Type answer here]\r\n"]},{"cell_type":"markdown","metadata":{"id":"sdOWI77nB2KU"},"source":["## Handle Missing Values\r\n","\r\n","Before feeding the data to ML algorithms we need to make sure the data is \"clean\". This means our data is in a form appropriate for your chosen algorithm(s). Real-world data are seldom clean. Typically we have missing values, or even data entered incorrectly.\r\n","\r\n","If a patient has some missing values, perhaps whoever was caring for that patient either forgot to measure the value or just failed to enter the data in the correct location in the EMR.\r\n","\r\n","**Run the Python command to count the number of zeros for each variable in the dataset.**"]},{"cell_type":"code","metadata":{"id":"WRSd4gGRGDnJ"},"source":["data.isin([0]).sum() # Count the number of zeros in each variable"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"bl94waMveHi1"},"source":["The Body Mass Index (BMI) is 0 for 11 patients. Impossible! In this case, nulls, were filled by the '0's. Since these '0's would affect the statistics of our data, we need to find a way to handle them.\r\n","\r\n","**Question 8** How many patients are missing a blood pressure (BP_SYS)?\r\n","\r\n","**Answer 8**     [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"Nbh0MhSzeeyD"},"source":["In the case of Glucose, BP_SYS and BMI, it may make sense to drop the missing data.\r\n","\r\n","But sometimes, we need to keep the data as is.\r\n","**Please note that for Insulin_YN, 0 does not indicate a missing value**\r\n","In this context it is a Boolean value meaning \"No\", the patient is not on insulin. *We must not change the values of the last column.*\r\n","\r\n","**Run the code to create a temporary dataset_minus_insulin without the last column**\r\n"]},{"cell_type":"code","metadata":{"id":"jg0OkABwf5Cf"},"source":["# Assign a new name, dataset_minus_insulin, to the dataset without the last column\r\n","\r\n","data_minus_insulin = data.columns[:-1]\r\n","\r\n","print('Insulin_YN dropped from data_minus_insulin')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"lKXj09GaHwZP"},"source":["# Run this code to \r\n","# Replace 0's in the data_minus_insulin with NaN (acronym for Not a Number). \r\n","# The expression \"!=\" means not equal in Python syntax\r\n","# \"inplace=True\" modifies the original data frame (rather than a copy)\r\n","\r\n","for column in data_minus_insulin:\r\n","  data[column].where(data[column] != 0, inplace=True)\r\n","  print('zeros replaced by NaN')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"ip4Kd3DVIjXg"},"source":["#Run this code to count how many \"NaN\" are in each column.\r\n","\r\n","data.isnull().sum() "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"C6pAkn2Vg3Tu"},"source":["\r\n","**Question 9** How do the null counts match up with the zeros we counted (just before question 8)?\r\n","\r\n","**Answer 9** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"Tavxe7N4Kw6f"},"source":["Now the NaN's are in place, the simplest solution is just to drop the rows with missing values. \r\n","\r\n","**Run the command to drop missing values**"]},{"cell_type":"code","metadata":{"id":"C-eTciiiLCYQ"},"source":["data.dropna()    #Drop NaN missing values"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FWsf-Io5LYZj"},"source":["**Question 10**  How many instances have been dropped? (Hint: Compare the number of rows). What percentage of the orignal row count was affected?\r\n","\r\n","**Question 10 Answer**  [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"3K0vEGDGL6Kr"},"source":["From a mathmatical perspective, there are no hard rules for knowing when to many rows have been dropped. However, for practical purposes, we'll say that we have sufficient data if the loss is <20%."]},{"cell_type":"markdown","metadata":{"id":"U-c_j0ChsX4e"},"source":["**Imputation** may be a better way to deal with the missing data. There are various techniques that may be used drive missing values. In all cases, they use the data surrounding the gap to \"guess\" at what the missing value might have been.\n","\n","**Run the code to apply the backfill method to impute the missing values in the dataset-insulin.**"]},{"cell_type":"code","metadata":{"id":"PVn8kuLpMqV7"},"source":["# Use the backfill method to impute the missing values\r\n","\r\n","data.fillna(method='backfill',inplace=True) #use next valid observation to fill gap.\r\n","print('imputation by backfill complete')\r\n","\r\n","data.head(10)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NdnKAjtkNUZH"},"source":["Observe the Blood pressure on row 7.  \r\n","\r\n","**Question 11**How does that compare with the original value right after we read the dataset?\r\n","\r\n","**Answer 11** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"1hG-J50RB_mn"},"source":["##Identify Outliers"]},{"cell_type":"markdown","metadata":{"id":"kmEGHkOUhcGa"},"source":["Another issue we need to handle is the presence of outliers. \r\n","\r\n","**Run the code below to create Seaborn boxplots for our data.**\r\n"]},{"cell_type":"code","metadata":{"id":"T5x8DrOzPWsx"},"source":["sns.boxplot(data = data[data_minus_insulin]); "],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"NJqc0GpQPcrt"},"source":["There are couple of issues we can learn form these plots. First, note that BP_SYS, BMI, and Age contain some data the can be considered as **outliers**. While we might be tempted to simply remove that outliers, there are issues that might arise from that naive approach. \r\n","\r\n","**Question 12** What problems might we encounter if we simply remove data we deem as outliers?\r\n","\r\n","**Answer 12** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"SEiMLY5WbcHh"},"source":["#**Step 3: Exploratory Data Analysis (EDA)**\n","\n","\n","**Run the code to create a pairplot**"]},{"cell_type":"code","metadata":{"id":"XbQnzNJjhDtb"},"source":["sns.pairplot(data=data, palette='dark');"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"8CwqscckQaIb"},"source":["**Have Fun**\r\n","\r\n","Use this opportunity to conduct additional EDA. You might enjoy trying out the Seaborn library or any other Python visualization technique using this data. Please add a code cell below and try at least one new command. Document your code and explain what you learned in a new text cell."]},{"cell_type":"markdown","metadata":{"id":"8stlDqUz7M5o"},"source":["#**Step 4: Build the Models and Evaluate**\r\n","\r\n","We're going to hold off on the models until the next lab. You will continue to use the techniques you're mastering here in the upcoming labs.\r\n","\r\n","You don't need to know all the commands of Pandas for this course. Even professional data scientists look up how to do things in libraries every single day. The best resources are https://stackoverflow.com/ where you can post questions. (Before you post please read the posting guidelines!)"]},{"cell_type":"markdown","metadata":{"id":"coTe6sxS7_Pq"},"source":["#**Turn it in**\r\n","\r\n","When all the questions are complete, and the code has been run, do a **File>Save**. Then print the notebook (**File>Print>As PDF**) and turn it in to Blackboard. Use the naming convention: HCIN620_Lab2_DataCleaning_[Name].pdf\r\n"]}]}