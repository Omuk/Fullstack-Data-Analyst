{"cells":[{"cell_type":"markdown","metadata":{"id":"ODbZkdZtib95"},"source":["$\\color{brown}{\\text{HCIN 620 Lab 4 Supervised Learning Using Classification Algorithms}}$\n","\n","In this lab we will learn to apply two ML classification algorithms to predict what causes heart disease. The dataset for this lab was made publicly available on Kaggle by Ronit using UCI de-identified cata donated by David W. Aha.\n","\n","[Heart Disease UCI data dictionary](https://www.kaggle.com/ronitf/heart-disease-uci)\n","\n","The original dataset is published at [link text](https://archive.ics.uci.edu/ml/datasets/Heart+Disease)\n","\n","The authors of the databases have requested that any publications resulting from the use of the data include the names of the principal investigator responsible for the data collection at each institution. They would be:\n","1. Hungarian Institute of Cardiology. Budapest: Andras Janosi, M.D.\n","2. University Hospital, Zurich, Switzerland: William Steinbrunn, M.D.\n","3. University Hospital, Basel, Switzerland: Matthias Pfisterer, M.D.\n","4. V.A. Medical Center, Long Beach and Cleveland Clinic Foundation:Robert Detrano, M.D., Ph.D.\n","\n","Notebook by Reza Afra, Ph.D. and Barbara Berkovich, Ph.D., M.A.\n","\n","Last update December 28, 2020"]},{"cell_type":"markdown","metadata":{"id":"24Cn0obpz_tO"},"source":["# **STEP 1: Environment Setup** "]},{"cell_type":"markdown","metadata":{"id":"adJct072ij93"},"source":["**Import Code Libraries**\n","\n","\n","<br/>**Question 1**<br/>\n","Using your knowledge from modules 2 and 3, type the code to import the libraries for pandas, numpy, matplotlib (ggplot) and seaborn. Add a print statement to acknowledge that this step has been run.\n","\n","**Run Import 1** for Input/output and plotting\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"o7dqWshI5wdV"},"outputs":[],"source":["# Answer 1: Type Import 1 code in this section\n","import pandas as pd \n","import numpy as np\n","\n"]},{"cell_type":"markdown","metadata":{"id":"MrGnwzeqjUK7"},"source":["**Import 2** The sklearn preprocessing classes include OrdinalEncoder, StandardScaler, train_test_split, and new classes you'll be introduced to later in the lab. We also bring in classes to evaluate the models. This import also supresses pesky warnings, resulting in a cleaner run package.\n","\n","**Run import 2** for preprocessing and evaluation libraries\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"sbes0-TzB7Xw"},"outputs":[],"source":["# Import 2 preprocessing and evaluation libraries\n","from sklearn.preprocessing import OrdinalEncoder, StandardScaler\n","from sklearn.model_selection import train_test_split\n","from sklearn.compose import ColumnTransformer\n","from sklearn.metrics import  accuracy_score, confusion_matrix\n","# Suppress pesky warnings\n","import warnings\n","warnings.filterwarnings(\"ignore\")\n","print ('Import 2 preprocessing and evaluation libraries complete')"]},{"cell_type":"markdown","metadata":{"id":"je2So1z6i-Ds"},"source":["\n","**Run Import 3** for machine learning algorithms."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Npp-e2DNB7Xx"},"outputs":[],"source":["# Import the models\n","from sklearn.linear_model import LogisticRegression\n","from sklearn.neighbors import KNeighborsClassifier\n","\n","print('Import 3 machine learning algorithms complete')"]},{"cell_type":"markdown","metadata":{"id":"zwvxVdOSj122"},"source":["# **STEP 2: Data Cleaning**"]},{"cell_type":"markdown","metadata":{"id":"Xql_hTolh8VM"},"source":["**Use the Folder and upload icons (left) to upload data-lab-4-heart.csv**\n","\n","**Run the code** to read the heart data in the Colab Runtime Environment."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"8Qd67dI-B7Xy"},"outputs":[],"source":["df = pd.read_csv('data-lab-4-heart.csv')\n","data = df.copy()\n","print('Data connection complete')"]},{"cell_type":"markdown","metadata":{"id":"NTVBlEQFj7go"},"source":["**Question 2** </br>\n","Insert the Python command to display first 10 rows of data and run it. Always look at the data before doing anything else.\n","\n","**Run the code.**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZpYcRjWSiplw"},"outputs":[],"source":["# Answer 2: Enter the command to generate a dataset header in this cell.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"GRI0ppULlCsx"},"source":[" Identify the categorical variables by inspections.  "]},{"cell_type":"markdown","metadata":{"id":"1zTtIiyZnksP"},"source":["**Question 3** Edit this text box to list the categorical variables\n","\n","Answer: Fill in categorical variable names on the list below. Add as many lines as needed.\n","\n","1.   **Type variable 1 name**\n","2.   **Type variable 2 name**"]},{"cell_type":"markdown","metadata":{"id":"We7mQZArneB_"},"source":["Here are the descriptions of each column.\n","*   **age** age\n","*   **sex** sex\n","*   **cp**  chest pain type (4 values)\n","*   **trestbps** resting blood pressure\n","*   **chol**    serum cholestoral in mg/dl\n","*   **fbs**     fasting blood sugar > 120 mg/dl\n","*   **restecg** resting electrocardiographic results (values 0,1,2)\n","*   **thalach**  maximum heart rate achieved\n","*   **exang**   exercise induced angina\n","*   **oldpeak** ST depression induced by exercise relative to rest\n","*   **slope**   the slope of the peak exercise ST segment\n","*   **ca**      number of major vessels (0-3) colored by flourosopy\n","*   **thal**    3 = normal; 6 = fixed defect; 7 = reversable defect\n","*   **target**  "]},{"cell_type":"markdown","metadata":{"id":"R4EP-LELkBOQ"},"source":["##Check for missing values\n","\n","\n","**Question 4** Enter the code to check for missing values, and then run it.\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AgbNK5UwjVgF"},"outputs":[],"source":["## Answer 4: Enter the code to check for missing values.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"9TMBARGotFVZ"},"source":["Another step in data cleaning involves checking for duplicate values. Before making any more changes to the dataset, determine the number of rows and columns in the dataset using the shape command.\n","\n","**Question 5** </br> Before making any more changes to the dataset, determine the number of rows and columns in the dataset using the shape command."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"6U4RJEY3khmk"},"outputs":[],"source":["#Answer 5: Enter the shape command in this cell, and run it."]},{"cell_type":"markdown","metadata":{"id":"aWnPBqn9277q"},"source":["## Check for duplicates\n","\n","\n","**Question 6** Enter the code to check for duplicates using the drop_duplicates command and run it.\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"1fsZ3a7elaNR"},"outputs":[],"source":["##Answer 6: Enter the drop_duplicates command\n","\n"]},{"cell_type":"markdown","metadata":{"id":"rwwZTnfJlxn0"},"source":["**Question 7** Repeat the shape command, and run it."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"kWSRqUnSmBY1"},"outputs":[],"source":["# Answer 7: Repeat the shape command \n","\n"]},{"cell_type":"markdown","metadata":{"id":"lPznJsq_maOR"},"source":["**Question 8** Edit this cell to answer the questions:\n","\n","**Answer 8**\n","1.  How many rows are there now? [Type answer here]\n","2.  How many duplicates were dropped? [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"SOJPBylJnnn6"},"source":["# **STEP 3: Exploratory Data Analysis (EDA) and Preprocessing**"]},{"cell_type":"markdown","metadata":{"id":"8C6dWtH6oYC9"},"source":["##Descriptive Statistics\n","\n","**Question 9** </br> Use the **describe** command to display descriptive statistics for continuous variables in the data frame. Include the .05 and .95 percentiles. Include the following columns in the table:\n","age, trestbps, chol, thalach, oldpeak."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"bma52BwEnSIc"},"outputs":[],"source":["## Answer 9 Enter the describe command in this cell.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"u34YnjY1p6pH"},"source":["**Question 10**\n","\n","Answer the following questions based on the table above.\n","\n","**Answer 10**\n","1.  How many people are in this dataset?    [Type answer here]\n","2.  What is the range of ages?           [Type answer here] \n","3.  List the mean and 50th percentile for Chol.  [Type answer here]\n","4.  Explain the difference between the mean and the 50th percentile. [Type answer here]\n","5.  What is the clinical significance? [Type answer here]\n","\n"]},{"cell_type":"markdown","metadata":{"id":"fuv4bVOCrKlc"},"source":["**Question 11** Let's look more closely at the distribution of cholestrol in patients. Enter the seaborn (sns) command to plot a histogram of chol."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uPGcknVeobxK"},"outputs":[],"source":["# Answer 11: Enter code to plot a histogram of cholesterol lab results\n"]},{"cell_type":"markdown","metadata":{"id":"GeBLd5aWoioN"},"source":["## Check for outliers\n","\n","**Question 12**  \n","Enter the seaborn (sns) command to generate a boxplot of chol."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M9-WozwVovzs"},"outputs":[],"source":["#Answer 12: Box Plot of Cholesterol \n","\n"]},{"cell_type":"markdown","metadata":{"id":"Y0GT-Q3gpCDL"},"source":["**Question 13** </br>\n","\n","Use the two plots to answer the following questions. Enter the answers in this text cell.\n","\n","**Answer 13**\n","\n","1. Are there outliers in cholestrol measurements? [Type answer here]\n","2. How many? [Type answer here]\n"]},{"cell_type":"markdown","metadata":{"id":"bzBmh5FAub63"},"source":["##Select target and features\n","\n","**The Target is what we want to predict.** In our pre-labeled dataset, the variable called \"target\" refers to the presence of heart disease in the patient. It is integer valued from 0 (no presence) to 4. \n","\n","**The Features are variables used by the model to predict the target.**\n","\n","**Question 14** \n","Edit this text cell with your answers to the following questions.\n","\n","**Answer 14**\n","1. Which features do you think might be the most important features in this dataset for predicting heart disease? [Type answer here]\n","2  Why? [Type answer here]\n"]},{"cell_type":"markdown","metadata":{"id":"MQZG4e7zp0jn"},"source":["**Question 15** \n","\n","Run a correlation table that shows how all of the columns correlate with the target variable. Sort the values in ascending order."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"cbhi2v9Pp0L3"},"outputs":[],"source":["## Answer 15: Enter the correlation of each column to the target\n","\n","\n"]},{"cell_type":"markdown","metadata":{"id":"Lbkx_CVHryWM"},"source":["**Question 16** Edit this text box to identify the top four features correlated with target? Remember that the magnitude of the correlation is more important than the sign (+/-).\n","\n","**Answer 16**\n","\n","1. [Type Feature 1 here], [type correlation value]\n","2. [Type Feature 2 here], [type correlation value]\n","3. [Type Feature 3 here], [type correlation value]\n","4. [Type Feature 4 here], [type correlation value]\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"hMBB90LjdnOd"},"outputs":[],"source":[]},{"cell_type":"markdown","metadata":{"id":"5Ce9L9AQqXr_"},"source":["Run the code below to generate a heatmap."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"mSDN-yDjB7X1"},"outputs":[],"source":["f, ax = plt.subplots(figsize=(10, 8))  \n","corr = data.corr()\n","sns.heatmap(corr, mask=np.zeros_like(corr, dtype=np.bool), cmap=sns.diverging_palette(240,10,as_cmap=True),\n","            square=True, ax=ax)"]},{"cell_type":"markdown","metadata":{"id":"JlKoQkYgKdrT"},"source":["Red is the highest correlation. The diagonal red line shows that each variable is 100% correlated with itself. Pink and light blue show weaker correlations.\n","\n","**Question 17**</br>\n"," List a few correlated features not identified in question 9, along with their approximate correlation coefficients. Estimate using the color legend on the right. \n","\n"," **Answer 17**\n","\n"," 1. [Type Pair 1 here], [correlation coefficient]\n"," 2. [Type Pair 2 here], [correlation coefficient]\n"," 3. [Type Pair 3 here], [correlation coefficient]"]},{"cell_type":"markdown","metadata":{"id":"CG52k5nhwfrP"},"source":["##Isolate features from target"]},{"cell_type":"markdown","metadata":{"id":"nGflW__Krsb8"},"source":["The first step in preprocessing is to create a features dataframe that does not include the target variable. Run the code below to do that. We assign the number of attributes (remaining columns) to the variable features. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"4KHgZfT2B7X2"},"outputs":[],"source":["features = data.drop([\"target\"], axis=1)\n","\n","print('features isolated')"]},{"cell_type":"markdown","metadata":{"id":"qindGzj0wlPv"},"source":["##Build pipeline for scaling and encoding\n","\n","You identified the categorical and continuous variables in questions 3 and 5 respectively. Now we perform a standard scaling on numerical columns and ordinal encoding on the categorical columns. The code to do this uses a pipeline to combine several transformations into one step. Then, the transformed data is assigned to X, and the target is assigned to Y. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3ltzMkQJB7X2"},"outputs":[],"source":["full_pipeline = ColumnTransformer([\n","    (\"num\", StandardScaler(), ['age','trestbps','chol','thalach','oldpeak']),   # All the categorical columns\n","    (\"cat\", OrdinalEncoder(), ['sex', 'cp', 'restecg', 'exang', 'slope', 'ca', 'thal']) ]) # All the non-categorical columns\n","x = pd.DataFrame(full_pipeline.fit_transform(features))\n","y = data[\"target\"] # pick the last column\n","\n","print('regression x and y assigned')\n"]},{"cell_type":"markdown","metadata":{"id":"x3D-m-g1xHZb"},"source":["**Question 18** <br>\n","Edit this text box to answer the questions below.\n","\n","**Answer 18**\n","\n","1. What justifies the use of ordinal encoding on our categorical columns? [Type answer here]\n","2. In what situations can we use ordinal encoding? [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"UEe08SGbyJ3d"},"source":["\n","\n","**Run the code** to view the transformed data."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Ev9lpARgrjmb"},"outputs":[],"source":["x.head()"]},{"cell_type":"markdown","metadata":{"id":"WJDl1nuXxd8N"},"source":["##Split the data"]},{"cell_type":"markdown","metadata":{"id":"FMpuLdcSsuPl"},"source":["Just like we did in Module 3 we split the data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uFm7EHouB7X3"},"outputs":[],"source":["TEST_SIZE = 0.3\n","RANDOM_STATE = 42 \n","\n","\n","X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=TEST_SIZE ,random_state=RANDOM_STATE )\n","\n","print('Splitting complete')"]},{"cell_type":"markdown","metadata":{"id":"nvAz_zno0UZC"},"source":["#**STEP 4: Build the Models** \n","The purpose of feature engineering in general is to find the best features for the least complex model. Here we take the easiest route and include all features to establish a baseline. Remember to always start from the simplest nontrivial model. In future tuning of the models, we may find that some features work better than others for predicting whether the patient has heart disease."]},{"cell_type":"markdown","metadata":{"id":"YciTDl57ymhL"},"source":["##Logistic Regression\n","\n","The first algorithm we are going to use is logistic regression.\n","\n","**Run the code** for training and testing the logistic regression model. The code outputs the level of accuracy between the predicted and test values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"lOgGLBGWB7X3"},"outputs":[],"source":["# Logistic Regression\n","log_reg = LogisticRegression()\n","log_reg.fit(X_train, y_train)\n","y_pred = log_reg.predict(X_test)\n","print(f' Accuracy on test set: {accuracy_score(y_test, y_pred):.3f}')"]},{"cell_type":"markdown","metadata":{"id":"eGaW1U_ohTtc"},"source":["##Confusion Matrix\n","\n","The confusion matrix is a visualization of the actual number of True Positives and Negatives, and False Positives and Negatives."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"2pTPKFpZB7X4"},"outputs":[],"source":["# Confusion Matrix\n","\n","data_ = {'y_true':y_test,\n","        'y_pred': y_pred\n","        }\n","\n","df = pd.DataFrame(data_, columns=['y_true','y_pred'])\n","confusion_matrix = pd.crosstab(df['y_true'], df['y_pred'], rownames=['TRUE'], colnames=['PREDICTED'])\n","\n","sns.heatmap(confusion_matrix, annot=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"7lgbExreyxUj"},"source":["##K-Nearest Neighbors\n","\n","<br/>The next classification algorithm is k-nearest neighbors. \n","\n","\n","**Run the code** for training and testing the k nearest neighbors model. The code outputs the level of accuracy between the predicted and test values."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"-hrMfVDDB7X4"},"outputs":[],"source":["knn = KNeighborsClassifier(n_neighbors=3)\n","knn.fit(X_train, y_train)\n","\n","y_pred = knn.predict(X_test)\n","print(f' Accuracy on test set: {accuracy_score(y_test, y_pred):.3f}')"]},{"cell_type":"markdown","metadata":{"id":"UQtwGZbYiOx6"},"source":["##Confusion Matrix\n","\n","The confusion matrix is a visualization of the actual number of True Positives and Negatives, and False Positives and Negatives."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"nIjnbco2B7X5"},"outputs":[],"source":["# Confusion Matrix\n","\n","data_ = {'y_true':y_test,\n","        'y_pred': y_pred\n","        }\n","\n","df = pd.DataFrame(data_, columns=['y_true','y_pred'])\n","confusion_matrix = pd.crosstab(df['y_true'], df['y_pred'], rownames=['TRUE'], colnames=['PREDICTED'])\n","\n","sns.heatmap(confusion_matrix, annot=True)\n","plt.show()"]},{"cell_type":"markdown","metadata":{"id":"kfcy-roQy7xy"},"source":["## Model Tuning\n","\n","Some models can be fine-tuned by changing processing parameters. In this case, we'd like to find out how many neighbors is optimal. To that end, we test from 1 to 20 neighbors. "]},{"cell_type":"code","execution_count":null,"metadata":{"id":"MCwmUfEgB7X5"},"outputs":[],"source":["# Find the optimal number of neighbors\n","accuracies = []\n","for N in range(1,20):\n","    knn = KNeighborsClassifier(n_neighbors=N)\n","    knn.fit(X_train, y_train)\n","    y_pred = knn.predict(X_test)\n","    acc = accuracy_score(y_test, y_pred)\n","    accuracies.append(acc)\n","    \n","accuracies = np.array(accuracies) # convert to numpy array\n","print('KNeighborsClassifier complete for 1-20 neighbors')\n"]},{"cell_type":"markdown","metadata":{"id":"OB2OwnyDjCk7"},"source":["**Run the code** to plot the accuracy of the model(x) based on the number of neighbors(y)."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"ZAROBFGHB7X6"},"outputs":[],"source":["sns.lineplot(np.arange(1,20),accuracies)"]},{"cell_type":"markdown","metadata":{"id":"dOteMJ8NjVEc"},"source":["**Question 19** Based on the linegraph, what is the optimal integer number of neighbors (which optimizes the accuracy).\n","\n","**Answer 19** [Type answer here]"]},{"cell_type":"markdown","metadata":{"id":"hOMQo4LHjqYx"},"source":["**Run the code** to check the answer mathematically."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XOHV42DwB7X6"},"outputs":[],"source":["# Find the best k\n","best_k = 1 + np.argmax(accuracies) # add one b/c arrays are 0-indexed\n","best_accuracy = np.max(accuracies)\n","print(f\"Best k: {best_k}  \\nBest Accuracy from kNN: {best_accuracy:.3f}\")"]},{"cell_type":"markdown","metadata":{"id":"wJfA2gCd05I8"},"source":["In this lab we saw that with very simple algorithms and no feature engineering, we were able to achieve 84.6% accuracy. There are more elaborate models and tricks that could be used to achieve better accuracy. Whether or not that would be a good idea depends on the intended use of the model predictions."]},{"cell_type":"markdown","metadata":{"id":"K55uQqrlkgP5"},"source":["**Have Fun** Try your hand at adding code to run another classification algorithm. Can you determine the accuracy? Did you beat the 84.6% accuracy of the K-nearest neighbors classification?"]}],"metadata":{"colab":{"collapsed_sections":[],"name":"Copy of HCIN620_M4_Lab4_Classification.ipynb","provenance":[{"file_id":"1_LdU8HSV5pJ59vcyKrK3sXfpXdZt7--R","timestamp":1609196962437}]},"kernelspec":{"display_name":"Python 3.10.5 64-bit","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.5"},"vscode":{"interpreter":{"hash":"d8648c7b4c41d7b1ba15281cf9494171032f5d76df8e8415c1b8fb59c6c5a947"}}},"nbformat":4,"nbformat_minor":0}
